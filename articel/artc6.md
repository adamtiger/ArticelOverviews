# Article Summary

**Title:** ACTOR-MIMIC DEEP MULTITASK AND TRANSFER REINFORCEMENT LEARNING <br/>
**Authors:** Emilio Parisotto, Jimmy Ba, Ruslan Salakhutdinov <br/>
**Year:** 2015

### Citation:

@article{parisotto2016actormimic, <br/>
  author    = {Emilio Parisotto and Lei Jimmy Ba and Ruslan Salakhutdinov}, <br/>
  title     = {Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning}, <br/>
  journal   = {CoRR}, <br/>
  volume    = {abs/1511.06342}, <br/>
  year      = {2015}, <br/>
  url       = {http://arxiv.org/abs/1511.06342}, <br/>
  archivePrefix = {arXiv}, <br/>
  eprint    = {1511.06342}, <br/>
  timestamp = {Wed, 07 Jun 2017 14:42:51 +0200}, <br/>
  biburl    = {https://dblp.org/rec/bib/journals/corr/ParisottoBS15}, <br/>
  bibsource = {dblp computer science bibliography, https://dblp.org} <br/>
}

### Abstract:

The ability to act in multiple environments and transfer previous knowledge to
new situations can be considered a critical aspect of any intelligent agent. 
Towards this goal, we define a novel method of multitask and transfer learning that
enables an autonomous agent to learn how to behave in multiple tasks simultaneously, 
and then generalize its knowledge to new domains. This method, termed
“Actor-Mimic”, exploits the use of deep reinforcement learning and model compression 
techniques to train a single policy network that learns how to act in a set
of distinct tasks by using the guidance of several expert teachers. We then show
that the representations learnt by the deep policy network are capable of 
generalizing to new tasks with no prior expert guidance, speeding up learning in novel
environments. Although our method can in general be applied to a wide range
of problems, we use Atari games as a testing environment to demonstrate these
methods.

## Overview

Here a structured but concise overview on the article is provided.

### Technical background


### Results, experiments


### Articles referred

